To fix the 404 error and the Certificate configuration while ensuring the .225 IP is correctly mapped to your Ingress, use the following sequence of commands.

I have cleaned up your steps to ensure they execute in the correct order and include the missing ingressClassName fix.

1. Install Cert-Manager
Bash

kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml
2. Create ClusterIssuer & Certificate
Bash

# Create the Issuer
cat <<EOF | kubectl apply -f -
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: awx-selfsigned-issuer
spec:
  selfSigned: {}
EOF

# Create the Certificate in the awx namespace
cat <<EOF | kubectl apply -n awx -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: awx-server-cert
spec:
  secretName: awx-server-tls-secret
  dnsNames:
    - awx-server-01.vgs.com
  issuerRef:
    name: awx-selfsigned-issuer
    kind: ClusterIssuer
    group: cert-manager.io
EOF
3. Configure Networking (.225 IP Move)
This moves the fixed IP from the AWX backend service to the NGINX Ingress Controller.

Bash

# 1. Make AWX service internal only
kubectl patch svc awx-prod-service -n awx -p '{"spec":{"type":"ClusterIP","loadBalancerIP":null}}'

# 2. Assign the .225 IP to the NGINX Ingress Controller
kubectl patch svc ingress-nginx-controller -n ingress-nginx -p '{"spec":{"type":"LoadBalancer","loadBalancerIP":"192.168.253.225"}}'

# 3. Force MetalLB to use the correct pool for Ingress
kubectl annotate svc ingress-nginx-controller -n ingress-nginx metallb.io/address-pool=awx-fixed-ip --overwrite
4. Update AWX Instance & Fix 404
This ensures the AWX Operator knows to use the nginx class (fixing the 404) and the TLS secret.

Bash

cat <<EOF | kubectl apply -n awx -f -
apiVersion: awx.ansible.com/v1beta1
kind: AWX
metadata:
  name: awx-prod
spec:
  service_type: ClusterIP
  ingress_type: ingress
  ingress_class_name: nginx
  hostname: awx-server-01.vgs.com
  ingress_tls_secret: awx-server-tls-secret
  admin_password_secret: awx-admin-password
  postgres_storage_class: longhorn
EOF

# Manual override fix for the Ingress Class (just in case)
kubectl patch ingress awx-prod-ingress -n awx -p '{"spec":{"ingressClassName":"nginx"}}'
5. Final Verification
Wait 30 seconds for the Ingress to reload, then run:

Bash

curl -vk https://awx-server-01.vgs.com/

==================================================================================================

kubectl patch svc longhorn-frontend -n longhorn-system -p '{"spec": {"type": "LoadBalancer"}}'

kubectl get svc longhorn-frontend -n longhorn-system


1. Enable strictARP in kube-proxy
Run this command to automatically patch the configuration. It switches strictARP from false to true in the kube-proxy ConfigMap:

Bash

kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e "s/strictARP: false/strictARP: true/" | \
kubectl apply -f - -n kube-system
After patching, restart the kube-proxy pods to apply the change:

Bash

kubectl edit configmap -n kube-system kube-pr

arp = true

kubectl rollout restart daemonset kube-proxy -n kube-system
2. Full Longhorn HTTPS Steps (Consolidated)
Step A: Configure Ingress Service for IP Sharing

Bash

# Allow multiple IPs on the controller
kubectl annotate svc ingress-nginx-controller -n ingress-nginx \
  metallb.io/allow-shared-ip="awx-longhorn-shared" --overwrite

# Bind both .220 and .225 to the controller
kubectl patch svc ingress-nginx-controller -n ingress-nginx -p '{"spec":{"externalIPs":["192.168.253.220", "192.168.253.225"]}}'
Step B: Issue the SSL Certificate

Bash

cat <<EOF | kubectl apply -n longhorn-system -f -
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: longhorn-server-cert
spec:
  secretName: longhorn-server-tls-secret
  dnsNames:
    - awx-longhorn-01.vgs.com
  issuerRef:
    name: awx-selfsigned-issuer
    kind: ClusterIssuer
    group: cert-manager.io
EOF
Step C: Create the Longhorn Ingress

Bash

cat <<EOF | kubectl apply -n longhorn-system -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: longhorn-ingress-https
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "10000m"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - awx-longhorn-01.vgs.com
    secretName: longhorn-server-tls-secret
  rules:
  - host: awx-longhorn-01.vgs.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: longhorn-frontend
            port:
              number: 80
EOF
Step D: Final Network Refresh

Bash

# Ensure the backend service is internal only
kubectl patch svc longhorn-frontend -n longhorn-system -p '{"spec": {"type": "ClusterIP"}}'

# Clean local ARP and resolve the host
ip neigh flush all
echo "192.168.253.220 awx-longhorn-01.vgs.com" >> /etc/hosts
Verification
Wait about 60 seconds for the pods to restart and the IP to settle, then test:

Bash

curl -vk https://awx-longhorn-01.vgs.com



