#!/bin/bash
set -e

# Detect non-boot pool automatically
POOL=$(zpool list -H -o name | grep -v boot-pool | head -n1)
DATASET="awx-postgres"
FULL_DATASET="${POOL}/${DATASET}"
MOUNTPOINT="/mnt/${POOL}/${DATASET}"

echo "======================================"
echo " TrueNAS NFS setup for Kubernetes AWX"
echo " Pool detected: ${POOL}"
echo "======================================"

if [ -z "$POOL" ]; then
  echo "ERROR: No ZFS pool detected!"
  exit 1
fi

# 1ï¸âƒ£ Create dataset if not exists
if zfs list | grep -q "^${FULL_DATASET}"; then
  echo "[1/5] Dataset already exists: ${FULL_DATASET}"
else
  echo "[1/5] Creating dataset ${FULL_DATASET}"
  zfs create ${FULL_DATASET}
fi

# 2ï¸âƒ£ Set mountpoint
echo "[2/5] Setting mountpoint..."
zfs set mountpoint=${MOUNTPOINT} ${FULL_DATASET}

# 3ï¸âƒ£ Ensure directory exists
echo "[3/5] Ensuring directory..."
mkdir -p ${MOUNTPOINT}

# 4ï¸âƒ£ Permissions (required for Kubernetes)
echo "[4/5] Setting permissions..."
chmod 777 ${MOUNTPOINT}

# 5ï¸âƒ£ Export NFS
echo "[5/5] Configuring NFS..."
grep -q "${MOUNTPOINT}" /etc/exports || \
  echo "${MOUNTPOINT} *(rw,sync,no_subtree_check,no_root_squash)" >> /etc/exports

exportfs -rav

echo "======================================"
echo " STEP 1 COMPLETE"
echo " NFS Export: ${MOUNTPOINT}"
echo "======================================"




root@truenas[~]# vi script_1.sh
root@truenas[~]# ./script_1.sh
======================================
 TrueNAS NFS setup for Kubernetes AWX
 Pool detected: truenas-nfs-postgres-kube
======================================
[1/5] Creating dataset truenas-nfs-postgres-kube/awx-postgres
[2/5] Setting mountpoint...
[3/5] Ensuring directory...
[4/5] Setting permissions...
[5/5] Configuring NFS...
exporting *:/mnt/truenas-nfs-postgres-kube/awx-postgres
======================================
 STEP 1 COMPLETE
 NFS Export: /mnt/truenas-nfs-postgres-kube/awx-postgres
======================================
root@truenas[~]#



#!/bin/bash
set -e

echo "======================================"
echo "Step 2: Installing NFS CSI Driver via Helm"
echo "======================================"

# Add CSI NFS Helm repository
helm repo add csi-driver-nfs https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
helm repo update

# Install the CSI NFS Driver into kube-system
helm upgrade --install csi-driver-nfs csi-driver-nfs/csi-driver-nfs \
  --namespace kube-system \
  --create-namespace

echo "Waiting 30s for CSI NFS driver pods to start..."
sleep 30

echo "Checking pods..."
kubectl get pods -n kube-system | grep csi-driver-nfs

echo "======================================"
echo "STEP 2 COMPLETE â€” NFS CSI Installed"
echo "======================================"


root@truenas[~]# midclt call sharing.nfs.create '{
  "path": "/mnt/truenas-nfs-postgres-kube/awx-postgres",
  "enabled": true,
  "ro": false,
  "maproot_user": "root",
  "maproot_group": "wheel",
  "hosts": []
}'

{"id": 1, "path": "/mnt/truenas-nfs-postgres-kube/awx-postgres", "aliases": [], "comment": "", "networks": [], "hosts": [], "ro": false, "maproot_user": "root", "maproot_group": "wheel", "mapall_user": null, "mapall_group": null, "security": [], "enabled": true, "locked": false, "expose_snapshots": false}
root@truenas[~]# midclt call service.restart nfs

True
root@truenas[~]# showmount -e 127.0.0.1

Export list for 127.0.0.1:
/mnt/truenas-nfs-postgres-kube/awx-postgres *
root@truenas[~]# exit
Connection to 192.168.253.141 closed.
[root@awx-control-node-01 ~]# showmount -e 192.168.253.141
Export list for 192.168.253.141:
/mnt/truenas-nfs-postgres-kube/awx-postgres *
[root@awx-control-node-01 ~]#



#!/bin/bash
set -e

echo "======================================"
echo "Step 3: Create NFS StorageClass + Test PVC"
echo "======================================"

NFS_SERVER="192.168.253.141"
NFS_PATH="/mnt/truenas-nfs-postgres-kube/awx-postgres"

cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: truenas-nfs
provisioner: nfs.csi.k8s.io
parameters:
  server: ${NFS_SERVER}
  share: ${NFS_PATH}
reclaimPolicy: Retain
volumeBindingMode: Immediate
allowVolumeExpansion: true
EOF

echo "StorageClass created"

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-test-pvc
  namespace: default
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: truenas-nfs
  resources:
    requests:
      storage: 5Gi
EOF

echo "PVC created"

echo "Waiting for PVC to bind..."
kubectl get pvc nfs-test-pvc -w



cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: nfs-debug
spec:
  containers:
  - name: nfs
    image: busybox
    command: ["sleep", "3600"]
    volumeMounts:
    - mountPath: /data
      name: nfsvol
  volumes:
  - name: nfsvol
    persistentVolumeClaim:
      claimName: nfs-test-pvc
EOF


kubectl get pod nfs-debug -w

kubectl exec -it nfs-debug -- sh


df -h
mount | grep nfs



[root@awx-control-node-01 ~]# clear
[root@awx-control-node-01 ~]# cat step_4.sh
#!/bin/bash
set -euo pipefail

echo "======================================"
echo " STEP 4: DEPLOY AWX WITH AUTO-PERMISSION FIX"
echo "======================================"

AWX_NAMESPACE="awx"
AWX_NAME="awx-prod"
STORAGE_CLASS="truenas-nfs"
PG_SIZE="20Gi"

# 1. CLEAN UP PREVIOUS ATTEMPT
echo "[1/6] Cleaning up old AWX instance..."
kubectl delete awx ${AWX_NAME} -n ${AWX_NAMESPACE} --ignore-not-found
kubectl delete pvc -l "app.kubernetes.io/name=postgres-15" -n ${AWX_NAMESPACE} --ignore-not-found

# 2. APPLY AWX CR
echo "[2/6] Applying AWX Custom Resource..."
cat <<EOF | kubectl apply -n ${AWX_NAMESPACE} -f -
apiVersion: awx.ansible.com/v1beta1
kind: AWX
metadata:
  name: ${AWX_NAME}
spec:
  service_type: LoadBalancer
  postgres_storage_class: ${STORAGE_CLASS}
  postgres_storage_requirements:
    requests:
      storage: ${PG_SIZE}
EOF

# 3. WAIT FOR PVC TO BE CREATED
echo "[3/6] Waiting for PVC to be created by Operator..."
until kubectl get pvc -n ${AWX_NAMESPACE} | grep -q "postgres-15"; do
  sleep 5
done
PVC_NAME=$(kubectl get pvc -n ${AWX_NAMESPACE} -o jsonpath='{.items[?(@.metadata.labels.app\.kubernetes\.io/name=="postgres-15")].metadata.name}')

# 4. RUN PERMISSION FIXER JOB
echo "[4/6] Running Permission Fixer Job for PVC: ${PVC_NAME}..."
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: nfs-permission-fixer
  namespace: ${AWX_NAMESPACE}
spec:
  template:
    spec:
      containers:
      - name: fixer
        image: busybox
        command: ["sh", "-c", "chown -R 26:26 /data && chmod -R 770 /data && ls -ln /data"]
        volumeMounts:
        - name: nfs-vol
          mountPath: /data
      restartPolicy: Never
      volumes:
      - name: nfs-vol
        persistentVolumeClaim:
          claimName: ${PVC_NAME}
EOF

# Wait for Job to finish
kubectl wait --for=condition=complete job/nfs-permission-fixer -n ${AWX_NAMESPACE} --timeout=60s
kubectl delete job nfs-permission-fixer -n ${AWX_NAMESPACE}

# 5. RESTART POSTGRES POD
echo "[5/6] Restarting Postgres to pick up new permissions..."
kubectl delete pod -l "app.kubernetes.io/name=postgres-15" -n ${AWX_NAMESPACE} --ignore-not-found

# 6. FINAL STATUS
echo "[6/6] Waiting for Postgres pod to be Ready..."
kubectl wait --for=condition=Ready pod -l "app.kubernetes.io/name=postgres-15" -n ${AWX_NAMESPACE} --timeout=300s

echo "======================================"
echo " AWX POSTGRES IS RUNNING SUCCESSFULLY ðŸŽ‰"
echo "======================================"
[root@awx-control-node-01 ~]#



kubectl get secret awx-prod-admin-password -n awx -o jsonpath="{.data.password}" | base64 --decode; echo
