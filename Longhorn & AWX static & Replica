
==========================================================================================================================================================================================================
=============================================================================================LONGHORN IP=================================================================================================
==========================================================================================================================================================================================================
cat <<EOF | kubectl apply -f -
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: awx-static-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.253.221-192.168.253.224
  - 192.168.253.226-192.168.253.230
---
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: longhorn-ip-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.253.220/32
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: awx-combined-adv
  namespace: metallb-system
spec:
  ipAddressPools: [awx-static-pool, longhorn-ip-pool]
EOF

# Annotate Longhorn frontend service to use dedicated IP pool
kubectl annotate svc longhorn-frontend -n longhorn-system metallb.universe.tf/address-pool=longhorn-ip-pool --overwrite

# Restart MetalLB controller to force IP reassignment
kubectl rollout restart deployment controller -n metallb-system

# Watch Longhorn service until it gets the external IP
kubectl get svc longhorn-frontend -n longhorn-system -w

==========================================================================================================================================================================================================
=============================================================================================AWX IP=================================================================================================
==========================================================================================================================================================================================================
 vi awx-static-pool.yaml

apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: awx-static-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.253.220-192.168.253.224
  - 192.168.253.227-192.168.253.230
  autoAssign: true
  avoidBuggyIPs: false

 kubectl apply -f awx-static-pool.yaml

 vi awx-fixed-ip.yaml

apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: awx-fixed-ip
  namespace: metallb-system
spec:
  addresses:
  - 192.168.253.226/32
  autoAssign: true
  avoidBuggyIPs: false
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: awx-fixed-adv
  namespace: metallb-system
spec:
  ipAddressPools:
  - awx-fixed-ip


 kubectl apply -f awx-fixed-ip.yaml

 kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/address-pool=awx-fixed-ip --overwrite

 kubectl rollout restart deployment controller -n metallb-system

 kubectl get svc awx-prod-service -n awx -w

FORCE

kubectl patch svc awx-prod-service -n awx -p '{"spec": {"loadBalancerIP": "192.168.253.225"}}'

kubectl rollout restart daemonset speaker -n metallb-system

kubectl get svc awx-prod-service -n awx

kubectl patch svc awx-prod-service -n awx -p '{"spec": {"type": "ClusterIP"}}'
# Wait 5 seconds
kubectl patch svc awx-prod-service -n awx -p '{"spec": {"type": "LoadBalancer"}}'

kubectl get svc awx-prod-service -n awx

kubectl patch l2advertisement awx-fixed-adv -n metallb-system --type='merge' -p '{"spec": {"interfaces": ["ens192"]}}'

# Remove the old deprecated spec field
kubectl patch svc awx-prod-service -n awx --type='json' -p='[{"op": "remove", "path": "/spec/loadBalancerIP"}]'

# Apply the specific IP request annotation (this is the modern way)
kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/loadBalancerIPs=192.168.253.225 --overwrite

# Ensure the pool is also targeted
kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/address-pool=awx-fixed-ip --overwrite

kubectl rollout restart deployment controller -n metallb-system

kubectl get svc awx-prod-service -n awx -w

kubectl describe deployment controller -n metallb-system

kubectl patch svc awx-prod-service -n awx --type=merge -p '{"status": {"loadBalancer": {}}}'

kubectl logs -n metallb-system -l component=controller --tail=50

kubectl exec -n metallb-system $(kubectl get pod -n metallb-system -l component=controller -o name) -- /controller --dump-config 2>/dev/null | grep -A 5 "awx-fixed-ip"

kubectl scale deployment controller -n metallb-system --replicas=0
# Wait 5 seconds
kubectl scale deployment controller -n metallb-system --replicas=1

kubectl edit ipaddresspool awx-static-pool -n metallb-system

Change the start range from .220 to .221.

kubectl logs -n metallb-system -l component=controller --all-containers

kubectl get svc awx-prod-service -n awx -w

XXXXXXXXXXXXXXXXXXXXXXXXX IP TROUBLESHOOING CMD XXXXXXXXXXXXXXXXXXXXXXXXX
kubectl get ipaddresspool -n metallb-system
kubectl logs -n metallb-system -l component=controller | grep -i "overlap"
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX



XXXXXXXXXXXXXXXXXXXXXXXXX EXACT IP CHANGE STEPS XXXXXXXXXXXXXXXXXXXXXXXXX

kubectl patch ipaddresspool awx-fixed-ip -n metallb-system --type='merge' -p '{"spec": {"addresses": ["192.168.253.226/32"]}}'

kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/loadBalancerIPs=192.168.253.226 --overwrite

kubectl get svc awx-prod-service -n awx -w

kubectl rollout restart deployment controller -n metallb-system

kubectl describe svc awx-prod-service -n awx

kubectl patch svc awx-prod-service -n awx --type='json' -p='[{"op": "remove", "path": "/spec/loadBalancerIP"}]'

# Clear the problematic annotations first
kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/loadBalancerIPs- metallb.universe.tf/address-pool-

# Re-apply them cleanly
kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/address-pool=awx-fixed-ip
kubectl annotate svc awx-prod-service -n awx metallb.universe.tf/loadBalancerIPs=192.168.253.226

kubectl get svc awx-prod-service -n awx

==========================================================================================================================================================================================================
==============================================================================================REPLICA===============================================================================================
==========================================================================================================================================================================================================


kubectl patch settings.longhorn.io storage-network-for-rwx-volume-enabled \
  -n longhorn-system --type=merge \
  -p '{"value":"true"}'


kubectl patch settings.longhorn.io rwx-volume-fast-failover \
  -n longhorn-system --type=merge \
  -p '{"value":"true"}'


kubectl get settings.longhorn.io -n longhorn-system | grep rwx


kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: longhorn-rwx
provisioner: driver.longhorn.io
parameters:
  numberOfReplicas: "3"
  staleReplicaTimeout: "30"
  fsType: ext4
  accessMode: ReadWriteMany
reclaimPolicy: Delete
volumeBindingMode: Immediate
EOF


kubectl get sc

kubectl edit awx awx-prod -n awx

spec:
  projects_storage_class: longhorn-rwx

kubectl get pods -n awx -w


kubectl edit awx awx-prod -n awx


replicas: 3              # web pods
task_replicas: 3         # task pods (production safe)
projects_storage_class: longhorn-rwx
postgres_storage_class: longhorn
projects_storage_access_mode: ReadWriteMany
service_type: LoadBalancer
loadbalancer_ip: 192.168.253.225

kubectl edit awx awx-prod -n awx



==========================================================================================================================================================================================================
===============================================================================================ISSUE=============================================================================================
==========================================================================================================================================================================================================

sudo modprobe br_netfilter

lsmod | grep br_netfilter

sudo sysctl -w net.bridge.bridge-nf-call-iptables=1
sudo sysctl -w net.bridge.bridge-nf-call-ip6tables=1


echo "br_netfilter" | sudo tee /etc/modules-load.d/br_netfilter.conf
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
sudo sysctl --system


kubectl delete pod -n kube-flannel -l app=flannel


==========================================================================================================================================================================================================
===============================================================================================FIXES=============================================================================================
==========================================================================================================================================================================================================


kubectl edit awx awx-prod -n awx


spec:
  tower_task_extra_env: []
  tower_web_extra_env: []
  tower_web_resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  tower_task_resources:
    requests:
      memory: "256Mi"
      cpu: "50m"
    limits:
      memory: "512Mi"
      cpu: "250m"

kubectl edit ds longhorn-manager -n longhorn-system

readinessProbe:
  httpGet:
    path: /v1/healthz
    port: 9502
    scheme: HTTPS
  initialDelaySeconds: 20  # Increase this (e.g., from 10 to 20 or 30)
  periodSeconds: 10
  timeoutSeconds: 3
  failureThreshold: 5      # Give it more chances to fail before restarting


kubectl -n longhorn-system delete pods --all--grace-period=0 --force


==========================================================================================================================================================================================================
===============================================================================================ENGINE NOT DEPLOYED=============================================================================================
==========================================================================================================================================================================================================





Engine not deployed

[root@awx-control-node-01 ~]# kubectl get volumes.longhorn.io -n longhorn-system
NAME                                       DATA ENGINE   STATE      ROBUSTNESS   SCHEDULED   SIZE         NODE                       AGE
pvc-514260df-ab6b-41e8-8a79-38e16533b81e   v1            attached   degraded                 8589934592   awx-work-node-02.vgs.com   6h41m
[root@awx-control-node-01 ~]#


# 1. Restart the Manager on Node-03
kubectl delete -n longhorn-system $(kubectl get pods -n longhorn-system --field-selector spec.nodeName=awx-work-node-03.vgs.com -l app=longhorn-manager -o name)

# 2. Restart the Instance Managers on Node-03
kubectl delete -n longhorn-system $(kubectl get pods -n longhorn-system --field-selector spec.nodeName=awx-work-node-03.vgs.com -l longhorn.io/component=instance-manager -o name)

kubectl patch volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system --type merge -p '{"spec":{"numberOfReplicas":3}}'

kubectl describe volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system | tail -n 20


kubectl patch volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system --type merge -p '{"spec":{"numberOfReplicas":2}}'
Wait 10 seconds.

Set back to 3:


kubectl patch volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system --type merge -p '{"spec":{"numberOfReplicas":3}}'

# On RHEL/CentOS/Rocky Linux (based on your 'rl-root' mapper name earlier)
yum install -y nfs-utils

kubectl delete -n longhorn-system $(kubectl get pods -n longhorn-system --field-selector spec.nodeName=awx-work-node-03.vgs.com -l app=longhorn-manager -o name)

kubectl patch volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system --type merge -p '{"spec":{"numberOfReplicas":3}}'

kubectl patch volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system --type merge -p '{"spec":{"numberOfReplicas":2}}'

kubectl patch volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system --type merge -p '{"spec":{"numberOfReplicas":3}}'

kubectl get replicas.longhorn.io -n longhorn-system | grep "awx-work-node-03"

kubectl describe volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system | grep -A 20 "Events:"

kubectl get nodes.longhorn.io awx-work-node-03.vgs.com -n longhorn-system -o jsonpath='{.status.diskStatus}'

kubectl get volumes.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e -n longhorn-system -o yaml | grep -i "Affinity"


==========================================================================================================================================================================================================
===============================================================================================IF STUCK ON REBUILDING=============================================================================================
==========================================================================================================================================================================================================




kubectl scale statefulset awx-prod-postgres-15 -n awx --replicas=0

# Delete the failed replica on Node-02
kubectl delete replica.longhorn.io pvc-514260df-ab6b-41e8-8a79-38e16533b81e-r-c47e0823 -n longhorn-system

kubectl scale statefulset awx-prod-postgres-15 -n awx --replicas=1

==========================================================================================================================================================================================================
===============================================================================================IF IP NOT REACHABLE AND WEB DIDN;T START=============================================================================================
==========================================================================================================================================================================================================

kubectl get endpoints awx-prod-service -n awx
kubectl scale statefulset awx-prod-postgres-15 -n awx --replicas=1
kubectl get pods -n awx -w
kubectl logs -n awx deployment/awx-operator-controller-manager -c manager --tail=50
kubectl logs -n awx deployment/awx-operator-controller-manager --all-containers --tail=50
kubectl logs awx-prod-postgres-15-0 -n awx --tail=50
kubectl delete pod -n awx -l control-plane=controller-manager

kubectl get deployments -n awx

kubectl get awx awx-prod -n awx -o yaml | grep -C 5 "memory"


kubectl scale deployment awx-prod-web -n awx --replicas=3
